Pandas E/S: trabajando con diferentes formatos de archivo
Realice este curso para Data Science y:
Comprenda qué son los archivos CSV, XLSX, JSON, HTML y XML
Comprenda cómo trabajar con diferentes tipos de datos, tanto de entrada como de salida (input/output)
Leer datos de Google Sheets
Obtener tablas de páginas web
Crear una base de datos local
Escribir en una base de datos local
Realizar consultas SQL
Aulas
Leyendo archivos CSV Ver el primer video
0 / 10
33min
Leyendo archivos Excel
0 / 10
40min
Leyendo archivos JSON
0 / 9
22min
Leyendo páginas en HTML e XML
0 / 10
22min
Leyendo banco de datos
0 / 12
52min
Formación con este curso

Python para Data Science

Instructor
instructor Alejandro Gamarra
Alejandro Gamarra
Linkedin

Github

Soy especialista en BI/Big Data, tengo +20 años de experiencia trabajando en las unidades de Data Science de Telefónica, con proyectos de Big Data a nivel mundial. Me emociona todo lo relacionado con Data Science e Inteligencia Artificial, y siento una verdadera devoción en compartir este conocimiento. Sígueme en mis redes sociales: ===============&gt; Linkedin: https://www.linkedin.com/in/ElProfeAlejo/ Youtube: https://www.youtube.com/@ElProfeAlejo/

Apoyo al aprendizaje
Icono de Luri
Luri, la IA de Alura
Habla con Luri para aclarar tus dudas y repasar el contenido de la clase. Conoce a Luri

Más sobre el curso
Foro del curso
**********************************************
*********************************************
01.Leyendo archivosCSV
01 Presentación
En esta clase, el instructor Alejandro Gamarra, también conocido como el Profesor Alejo, da la bienvenida a los estudiantes al entrenamiento de Python enfocado en la entrada y salida de datos. El objetivo principal es aprender a leer y escribir diferentes formatos de archivos, lo cual es fundamental para los científicos de datos en su trabajo diario.

Durante el curso, se abordarán varios tipos de archivos, incluyendo CSV, Excel, JSON, HTML, XML y bases de datos SQL. Cada tipo de archivo será explorado a través de casos de uso específicos, lo que permitirá a los estudiantes familiarizarse con la manipulación de diferentes tipos de información.

El profesor anima a los estudiantes a comenzar el curso y promete una experiencia educativa enriquecedora.
**********************************************************
02
Preparando el ambiente
 Siguiente pregunta

Antes de empezar…

Google Collaboratory, o Colab para abreviar, es una herramienta gratuita basada en la nube que le permite ejecutar y escribir código Python sin necesidad de configurar software ni hardware local. Es una excelente herramienta para ejecutar código de análisis de datos y otros tipos de proyectos de programación.

Para comenzar a utilizar la plataforma es necesario tener una cuenta de Gmail. Si aún no tienes una, deberás crearla. Después de iniciar sesión, vaya a la página de Google Colab y haga clic en el menú superior en "Archivo" y elija la opción "Nuevo cuaderno". Es el banco de trabajo de Colab donde puedes escribir y ejecutar código Python.

Colab se ejecuta en los servidores de Google, por lo que proporciona una máquina virtual en la nube con recursos como CPU, memoria y espacio en disco. Para ejecutar un código, simplemente escríbalo en una celda de código y haga clic en el botón "Ejecutar" o presione Shift + Enter.

Para seguir el desarrollo de los proyectos a lo largo del curso y reproducir todo lo realizado, puedes descargar los archivos iniciales aquí .

¿Vamos a empezar?
****************************************************************
03
Importando archivos CSV
En esta clase, aprendimos cómo importar y leer archivos CSV utilizando la biblioteca Pandas en Python. Comenzamos con un caso práctico en el que trabajamos para una cadena de supermercados que necesita identificar a sus mejores clientes para ofrecerles un descuento. Para ello, se nos proporcionó un archivo CSV llamado SuperStoreData.csv, que contiene información sobre los clientes.

Primero, se explicó cómo subir el archivo a Google Colab y luego se importó la biblioteca Pandas, asignándole el alias pd. Utilizamos el método read_csv de Pandas para leer el archivo CSV y almacenar su contenido en un DataFrame, que es una estructura de datos más fácil de manejar y analizar.

También se mostró cómo inspeccionar las primeras cinco líneas del DataFrame utilizando el método head, lo que nos permitió ver la información de manera tabular. Además, se discutió qué sucede si el archivo CSV utiliza un separador diferente, como el punto y coma, y se planteó la pregunta sobre cómo resolver este problema en la lectura de archivos.

En resumen, la clase se centró en la importancia de importar datos correctamente y cómo Pandas facilita este proceso al transformar archivos CSV en DataFrames para un análisis más efectivo.
***********************************************************
04
Para saber más: error de codificación - ¿cómo solucionarlo?
 Siguiente pregunta

Giovanna es una científica de datos que trabaja en una empresa de comercio electrónico. Ella es responsable de analizar datos de ventas para identificar patrones y tendencias que puedan ayudar a la empresa a tomar decisiones informadas.

Recientemente, le asignaron una nueva tarea: analizar un archivo CSV que contiene información sobre las ventas de la empresa durante un período determinado. Para ello, Giovanna intentó leer un archivo CSV en Google Colab, usando la biblioteca Pandas con el siguiente comando:

import pandas as pd
df = pd.read_csv('datos.csv')
Copia el código
Sin embargo, apareció el siguiente error:



En español, el mensaje significa UnicodeDecodeError: el códec 'utf-8' no puede decodificar el byte 0xff en la posición 0: byte de inicio inválido

Pero ¿qué significa eso? ¿Qué es esto de UTF-8?

El error de encoding ocurre cuando la biblioteca Pandas no puede interpretar correctamente los caracteres en un archivo CSV. Esto puede suceder cuando contiene caracteres especiales que la biblioteca Pandas no reconoce o cuando se guardó en un formato de codificación diferente al esperado.

Para resolver este error, es necesario identificar la codificación correcta del archivo CSV y especificarla al cargar el archivo con la biblioteca Pandas. Esta codificación predeterminada es UTF-8, pero en algunos casos, es posible que el archivo se haya guardado con una codificación diferente, como ISO-8859-1.

UTF-8 es una codificación de caracteres universal que se utiliza para representar caracteres de diferentes idiomas de una manera compatible con Internet y los sistemas de computadora en general. Las siglas UTF significan Unicode Transformation Format (Formato de Transformación Unicode) y el número 8 indica que esta codificación asocia una secuencia de 1 a 4 bytes (8 a 32 bits) a cada carácter.

La codificación UTF-8 se usa ampliamente en Internet y en sistemas informáticos de todo el mundo, ya que permite representar caracteres de diferentes idiomas en un solo conjunto de caracteres. Además, esta codificación puede preservar la compatibilidad con codificaciones más antiguas como ASCII, lo que la convierte en una opción popular para crear y compartir archivos de texto.

Quizás estés pensando ahora mismo: ¿cómo podría Giovanna descubrir cuál es la codificación del archivo que está intentando leer?

Hay algunas formas de resolver esto, sin embargo, tendremos la oportunidad de experimentar una forma práctica de hacerlo en el propio Google Colab. ¿Vamos allá?

Podemos usar una biblioteca llamada chardet para detectar el encoding de un archivo CSV. Para usar esta biblioteca en Google Colab, simplemente importela:

import chardet
Copia el código
Luego escribimos el siguiente bloque de código:

with open('datos.csv', 'rb') as file:
    print(chardet.detect(file.read()))
Copia el código
Observe que la primera línea de este código abre el archivo CSV en modo de lectura binaria rb y asigna el objeto del archivo devuelto a una variable llamada file.

En la segunda línea de código, el contenido del archivo CSV se lee usando el método read() y el resultado se pasa a la función chardet.detect(), que devuelve un diccionario que contiene información sobre la codificación más probable del archivo. El resultado se imprime con la función print() que muestra la codificación y la confianza asociada con esa codificación.

Al ejecutar el código Giovanna obtuvo el siguiente resultado:

{'encoding': 'UTF-16', 'confidence': 1.0, 'language': ''}
Copia el código
Ahora ella sabe que es probable que el archivo CSV esté codificado con UTF-16 con una confianza de 1.0. Para especificar la codificación correcta al cargar el archivo CSV con la biblioteca Pandas, puede utilizar un parámetro llamado encoding:

df = pd.read_csv('datos.csv', encoding='UTF-16')
Copia el código
De esta manera, la biblioteca Pandas cargará el archivo CSV usando la codificación UTF-16, lo que resolverá el error de codificación. Entonces, si alguna vez intentas leer un archivo y obtienes el mismo error, ¡recuerda este consejo!

Si deseas profundizar más en el tema, aquí te dejamos algunos enlaces a materiales que fueron utilizados como referencia:

Instituto de Matemáticas y Estadística - IME/USP: Unicode y UTF-8
IBM: ¿Qué es Unicode?
Kaggle: codificaciones de caracteres
**********************************************************************+
05
Parámetros de la función read_csv
En esta clase, aprendimos sobre la función read_csv de Pandas, que se utiliza para leer archivos CSV. Se destacó que esta función tiene alrededor de 30 parámetros que permiten personalizar la lectura de los archivos. Uno de los parámetros más importantes que se discutió fue sep, que define el separador utilizado en el archivo. Por defecto, read_csv asume que el separador es una coma, pero si el archivo utiliza otro separador, como un punto y coma, es necesario especificarlo.

También se exploraron otros parámetros como nrows, que permite leer solo un número específico de filas del archivo, y usecols, que permite seleccionar solo ciertas columnas para importar al DataFrame. Se mostró cómo utilizar estos parámetros para optimizar la lectura de datos y hacerla más eficiente.

Finalmente, se mencionó que en la próxima clase se aprenderá a exportar archivos a CSV, continuando así el proceso de manejo de datos con Pandas.	
//////////////////////////////////////////////////////////////////////////////////////////
06
Leyendo un archivo CSV
 Siguiente pregunta

Juliana está trabajando en un proyecto de análisis de datos de ventas para una tienda minorista. Ella recibió un conjunto de datos en formato CSV con los valores separados por punto y coma y necesita importarlo a un DataFrame de la biblioteca Pandas para iniciar el análisis.

¿Cuál es la forma correcta de leer este archivo CSV usando la biblioteca Pandas?

Alternativa correta
pd.read_csv(‘datos_ventas.csv’, sep=‘;’)

Al leer un archivo CSV con la biblioteca Pandas, es importante especificar el separador de campo correcto usando el parámetro sep. La opción predeterminada es una coma (','), por lo que debemos agregar el separador ;

Alternativa correta
pd.read_csv(‘datos_ventas.csv’)

Alternativa correta
pd.read_csv(‘datos_ventas.txt’)

Alternativa correta
pd.read_csv(‘datos_ventas’)

¡Enhorabuena, has acertado!
 Discutir en el Foro
 Siguient
******************************************************
07
Escribiendo archivos CSV
En esta clase, aprendimos cómo exportar un DataFrame en Python a un archivo CSV utilizando la función to_csv. Primero, se explicó que para guardar los datos, se debe especificar el nombre del DataFrame que queremos exportar, en este caso datos_selecion, y luego utilizar el método to_csv con el nombre del archivo que queremos crear, como clientes_mercado.csv.

Se mencionó un detalle importante: al exportar, el índice del DataFrame se convierte en una nueva columna en el archivo CSV. Para evitar esto, se puede utilizar el parámetro index y establecerlo en false, lo que evitará que el índice se incluya como columna en el archivo exportado. Así, se creó un nuevo archivo llamado datos_mercado.csv sin la columna del índice.

Finalmente, se recomendó revisar la documentación del método to_csv para personalizar aún más la exportación de datos. En la próxima clase, se abordará el trabajo con archivos Excel, que son diferentes de los archivos CSV.
**********************************************************
08
Para saber más: explorando la documentación
 Siguiente pregunta

La biblioteca Pandas es una de las herramientas más poderosas disponibles para análisis de datos en Python. Ofrece una amplia variedad de funciones que hacen que el proceso de manipulación y análisis de datos sea mucho más fácil y eficiente.

Para aprovechar al máximo todas las funciones de la biblioteca, es esencial explorar su documentación, que es extensa y está bien organizada, y a la que se puede acceder fácilmente en línea. Consulta las indicaciones:

Función read_csv
~ https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html
Función to_csv
~ https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html

Explorar la documentación de la biblioteca es importante por varias razones. Puede ayudarle a comprender cómo las funciones y métodos de la biblioteca funcionan y cómo se pueden utilizar para analizar y manipular datos.

Además, la documentación proporciona detalles sobre los parámetros de cada función y ejemplos de cómo se pueden utilizar en la práctica. Entonces, intenta profundizar tus estudios sobre los parámetros de cada función read_csv y to_csv y aprende más sobre cada uno de ellos.
*********************************************************+
09
Desafío: leyendo datos con múltiples parámetros
 Siguiente pregunta

Es hora de que pongas a prueba los conocimientos desarrollados durante la clase. Disponemos de un archivo en formato CSV, el cual se obtuvo de la página Información de Salud (TABNET) - DATASUS. Este archivo contiene los gastos hospitalarios públicos de cada una de las Unidades de la Federación Brasileña desde enero de 2008 hasta marzo de 2021.

Su desafío aquí será leer este archivo usando la función read_csv de la biblioteca Pandas. Se deben agregar algunos parámetros para que la lectura se realice correctamente. Entonces, aquí hay algunos consejos:

Asegúrese de que el archivo CSV esté separado por una coma o punto y coma.
La codificación del archivo es ISO-8859-1.
Las primeras tres líneas del archivo se pueden ignorar, ya que el encabezado sólo comienza en la cuarta línea.
Las últimas 9 líneas también se pueden ignorar, ya que son sólo información sobre dónde se tomaron los datos.
Para eliminar las últimas líneas es necesario agregar el parámetro engine='python'.
¿Comenzamos?

Ver opinión del instructor
Opinión del instructor

Para leer el archivo podemos comenzar almacenando la dirección en una variable llamada url:

url = 'datos_sus.csv'
Copia el código
Luego podemos leer la url con la función read_csv y agregar los parámetros:

encoding='ISO-8859-1': tipo de codificación de caracteres del archivo. En este caso, es la codificación ISO-8859-1 la que es común en los archivos en idioma portugués.
sep=';': separador de los valores del archivo. En este caso, es el punto y coma (;).
skiprows=3: indica que las primeras tres líneas del archivo deben ignorarse ya que no contienen datos relevantes.
skipfooter=9: Indica que las últimas nueve líneas del archivo deben ignorarse ya que no contienen datos relevantes.
engine='python': el motor utilizado para leer el archivo es Python. Esto es necesario cuando se utiliza el parámetro skipfooter, ya que el motor predeterminado no admite esta opción.
datos = pd.read_csv(url, encoding='ISO-8859-1', sep=';', skiprows=3, skipfooter = 9, engine='python')
Copia el código
¡De esta manera los datos se cargarán exitosamente!
**********************************************************
10
Lo que aprendimos
 Siguiente pregunta

En esta aula, aprendimos:

Entender qué es un archivo CSV;
Leer un archivo en formato CSV separado por comas y punto y coma;
Leer sólo unas pocas líneas y también columnas específicas de un archivo en formato CSV;
Escribir un archivo en formato CSV.
**********************************************************************
*******************************************************************
02. Leyendo archivos excel
01 Proyecto del aula anterior
Si lo desea, puede descargar aquí el proyecto del curso en el punto donde paramos la clase anterior.
*******************************************+
02
Importando archivos Excel
En esta clase, aprendimos a importar y trabajar con archivos de Excel utilizando la biblioteca pandas en Python. Comenzamos por entender qué es un archivo de Excel y sus características, como las filas, columnas y hojas que puede contener. Luego, se explicó cómo acceder a un archivo de Excel en Google Sheets y cómo este se diferencia de un archivo CSV.

A continuación, se mostró cómo importar un archivo de Excel en Google Colab, utilizando el método read_excel de pandas. Se enfatizó la importancia de guardar el nombre del archivo en una variable para optimizar el código. También se mencionó que al importar un archivo de Excel, el resultado se convierte automáticamente en un dataframe.

Finalmente, se presentó cómo examinar las hojas dentro de un archivo de Excel utilizando el método sheet_names, lo que permite conocer las diferentes hojas disponibles para trabajar. La clase concluyó con la promesa de explorar más sobre cómo seleccionar hojas específicas en el próximo video.

Si tienes alguna pregunta o necesitas más detalles sobre algún aspecto, ¡estaré encantado de ayudarte!
******************************************************
03 Para saber más: profundizando en la función read_excel
 Siguiente pregunta

Microsoft Excel es una de las herramientas de hojas de cálculo más utilizadas en el mundo, siendo ampliamente utilizada para almacenar y analizar datos en formato de tabla. En el video anterior, mostramos cómo la función read_excel se puede usar para leer un archivo de Excel en formato xlsx. Sin embargo, esta función es capaz de leer archivos en otros formatos, como: xls, xlsm, xlsb, odf, ods y odt.

¿Vamos a entender un poco más sobre estos diferentes tipos de archivos?

xls

El formato xls es un formato de archivo de Excel más antiguo y se utilizó hasta la versión de 2003.

xlsx

El formato xlsx es el formato de archivo de Excel predeterminado a partir de la versión 2007. Este formato se basa en XML(Extensible Markup Language - Lenguaje de marcación extensible) y es ampliamente compatible con otras herramientas de hojas de cálculo online, incluida Google Sheets.

Atención : Si tienes dudas sobre el término XML, ¡no te preocupes! Tendremos un aula sobre este tema más adelante. En ella entenderás qué es este formato, cómo leer y escribir en XML.

xlsm

También existe xlsm, una extensión de archivo utilizada por Excel para almacenar hojas de cálculo que contienen macros. Son secuencias de comandos o instrucciones que se pueden ejecutar automáticamente para realizar tareas específicas en la hoja de trabajo.

Entonces, el formato xlsm permite guardar las macros junto con la hoja de trabajo, de modo que puedan ejecutarse cada vez que se abra la hoja de trabajo.

xlsb

Por último, tenemos el formato xlsb, una extensión de archivo que utiliza Excel para almacenar hojas de cálculo en formato binario. La codificación binaria permite abrir y guardar hojas de cálculo más rápido que aquellas en formato xlsx.

Los formatos odf, ods y odt son archivos abiertos, gratuitos y universales que pueden ser utilizados por cualquier software, es decir, fueron creados para ser independientes de plataformas, esto quiere decir que pueden ser utilizados en diferentes sistemas operativos, como Windows, Linux y Mac OS.

Además, son independientes de aplicaciones y se pueden utilizar en muchos programas diferentes, incluidos OpenOffice, LibreOffice, Google Docs y Microsoft Office. Este estándar de archivos fue creado y es mantenido por OASIS (Organization for the Advancement of Structured Information Standards), una organización internacional creada para desarrollar y promover estándares digitales para su uso en Internet.

¡Muy bien! Ahora sabemos un poco más sobre todos los tipos de archivos que se pueden leer con la función read_excel.

Si deseas profundizar más en el tema, aquí te dejamos algunos enlaces a materiales que fueron utilizados como referencia:

Formatos de archivo compatibles con Excel
~ https://support.microsoft.com/es-es/office/formatos-de-archivo-que-admite-excel-0943ff2c-6014-4e8d-aaea-b83d51d46247
OpenDocument
~ https://pt.wikipedia.org/wiki/OpenDocument
****************************************************************
04 Parámetros de la función read_excel
En esta clase, aprendimos a utilizar la función read_excel de la biblioteca Pandas para leer archivos Excel. Se destacó el uso del parámetro SheetName, que permite abrir una hoja específica dentro del archivo. Se mostró cómo almacenar el resultado en una variable y cómo utilizar métodos como HEAD, TAIL y SAMPLE para examinar los datos de la hoja seleccionada.

Además, se introdujeron los parámetros nRows y useCols, que permiten restringir la cantidad de filas y columnas que se leen del archivo. Se explicó cómo seleccionar un intervalo de columnas (por ejemplo, de A a D) y cuántas filas (como las primeras diez) se querían incluir en el análisis. Finalmente, se mencionó que en la próxima clase se aprenderá a exportar el DataFrame a un archivo Excel.

Si tienes alguna duda específica sobre esta clase, ¡estaré encantado de ayudarte!
//////////////////////////////////////////////////////////////////////////////////////////////////
05 Leyendo intervalos
 Siguiente pregunta

Théo está trabajando en una análisis de datos en Python utilizando la biblioteca Pandas. Él está utilizando una hoja de cálculo de Excel que tiene 4 páginas y quiere leer sólo una de las tablas contenidas en una de ellas. La tabla que quiere leer está en la página "pagos" y los datos están en las primeras 50 filas desde la columna F hasta la columna L de la hoja de cálculo.

¿Cuál es el código correcto que debería usar Théo para leer sólo el intervalo deseado?

Alternativa correta
df = pd.read_excel('datos.xlsx', sheet='pagos', usecols='F:L', nrows=50)

Alternativa correta
df = pd.read_excel('datos.xlsx', sheet_name=’pagos’, interval='F:L',  nrows=50)

Alternativa correta
df = pd.read_excel('datos.xlsx', sheet_name='pagos', usecols='F-L', nrows=50)

Alternativa correta
df = pd.read_excel('datos.xlsx', sheet_name=’pagos’, usecols='F:L', nrows=50)

El parámetro sheet_name se utiliza para especificar la página de la hoja de cálculo que Théo quiere leer. En este caso, es la página "pagos". El parámetro usecols se utiliza para especificar las columnas que se leerán, que son las columnas de la F a la L. Además, el parámetro nrows se agregó para especificar el número de líneas que Théo quiere leer, que es 50.
****************************************************************
06 Escribiendo archivos Excel
En esta clase, aprendimos cómo exportar un dataframe de Pandas a un archivo Excel. Primero, se destacó la importancia de seleccionar el dataframe correcto, en este caso, intervalo, que contiene toda la información necesaria para el análisis.

El proceso de exportación es sencillo: se utiliza el método to_excel, cambiando la palabra "csv" por "excel" en comparación con el método que se usa para archivos CSV. Se debe especificar el nombre del archivo, como CO2_per_capita.xlsx, y es crucial añadir la extensión .xlsx. Además, se debe establecer index=False para no incluir el índice en el archivo exportado.

Después de exportar, se mostró cómo leer el archivo Excel recién creado utilizando el método read_excel, asegurándose de que los datos se hayan exportado correctamente. Finalmente, se mencionó la posibilidad de trabajar con archivos de Excel en línea, dejando la curiosidad para la próxima clase.

Si tienes alguna pregunta o necesitas más detalles sobre algún aspecto, ¡no dudes en preguntar!
******************************************************+
07 Para saber más: importando hacia Google Sheets
 Siguiente pregunta

Google Sheets es una herramienta de hojas de cálculo online basada en nube que le permite crear, editar y colaborar en hojas de cálculo de manera fácil y conveniente. Es una de las aplicaciones de Google Workspace que ofrece una alternativa a Microsoft Excel.

Con Google Sheets se puede crear y formatear hojas de cálculo, agregar fórmulas y funciones, crear gráficos y tablas dinámicas y trabajar con otros usuarios con datos en tiempo real. También admite la importación y exportación de varios formatos de archivos, como CSV y XLSX.

Una de las principales ventajas de Google Sheets es la colaboración en tiempo real. Varias personas pueden trabajar simultáneamente en la misma hoja de trabajo y ver los cambios simultáneamente. Esto facilita el trabajo en proyectos de equipo, aumentando la eficiencia y la productividad.

Para importar el archivo de Excel emisiones_CO2.xlsx hacia Google Sheets, siga estos pasos:

Abra la página de Google Sheets y haga clic en "Ir a Sheets". Inicie sesión en su cuenta de Google si es necesario.
Haga clic en Nueva Hoja de cálculo en blanco.
Cuando haya abierto, haga clic en "Archivo" (File) en el menú superior y luego haga clic en la opción "Importar archivo" (Import).
Haga clic en la pestaña "Subir" (Upload) y seleccione el archivo que desea importar. Puede hacer clic en la opción Examinar para ubicar el archivo en su computadora o arrastrar el archivo dentro de la pestaña.
Espere mientras se carga el archivo. Cuando se complete la carga, verá un mensaje de confirmación y podrá hacer clic en "Importar datos" (Import data).
Después de importar, se mostrarán los datos.
¡Excelente! Los datos se han importado correctamente. En el siguiente video, aprenderá cómo leer estos datos en Google Colab usando el link para compartir de Google Sheets.
********************************************************************+
08 Leyendo datos de Google Sheets
En esta clase, aprendimos cómo importar archivos de Excel que se encuentran en Google Sheets a nuestros DataFrames en Google Colab. Se explicó el proceso de compartir el archivo de Google Sheets para obtener un enlace que nos permita acceder a los datos.

Primero, se identificó el id del archivo, que es esencial para poder acceder a él. Luego, se mostró cómo construir una URL que incluya el id y otros parámetros necesarios, como gbiz, tq, y tqx.out:csv, para especificar el formato de salida como CSV.

Se explicó cómo utilizar fStrings para combinar texto y variables en Python, lo que facilita la creación de URLs más limpias y manejables. Además, se discutió cómo seleccionar diferentes hojas de un mismo archivo de Excel, utilizando una variable para el nombre de la hoja que se desea abrir.

Finalmente, se demostró cómo leer los datos en formato CSV utilizando pd.read_csv y cómo almacenar esos datos en variables para su posterior análisis. La clase concluyó enfatizando la posibilidad de trabajar con archivos de Excel tanto físicos como en línea.
**********************************************************
09 Desafío: leyendo datos de otro link
 Siguiente pregunta

Es hora de que pongas a prueba los conocimientos desarrollados durante la clase. Tenemos un link de Google Sheets que contiene datos importantes sobre las emisiones de dióxido de carbono en todo el mundo. El conjunto de datos se obtuvo de Kaggle y consta de las emisiones de CO2 per cápita de todos los países del mundo entre 1990 y 2019.

En este desafío, tu función es leer este link de Google Sheets y luego guardar el DataFrame obtenido en formato CSV. ¿Listo para comenzar?

Ver opinión del instructor
Opinión del instructor

Iniciemos creando una variable que recibirá el ID de la hoja de trabajo.

¿Y dónde encontramos ese id? En el propio link. Es todo lo que aparece entre d/ y /edit.
Copia el código
sheet_id = '1clj6rGaGlvZaLto2lgfFA7lodefC0OJgC86WgDm1nMU'
Copia el código
A continuación, creamos una variable que almacenará la dirección URL, pero podemos facilitar la escritura usando una f string para el sheet_id. Después de sheet_id tenemos algunos parámetros que se deben agregar.

En este primer momento es importante acceder a la API de visualización de datos de Google. Esto permitirá mostrar los datos de la hoja de cálculo de Google Sheets en Google Colab. Entonces, el parámetro gviz/tq indica que desea acceder a la función de consulta de datos de la API de visualización de datos.

La API también proporciona una forma de recuperar datos de hojas de cálculo como CSV, que es uno de los formatos que puede leer la biblioteca Pandas. Por este motivo indicamos el uso del parámetro tqx=out:csv para que los datos se devuelvan en formato CSV. El parámetro sheet recupera todos los datos de la hoja de trabajo, incluidos los encabezados de las columnas y las filas de datos.

url = f'https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet'
Copia el código
Una vez hecho esto, podemos leer los datos pasando la variable url a la función read_csv:

datos = pd.read_csv(url)
Copia el código
Para guardar los datos en formato CSV, basta con utilizar la función to_csv y, entre paréntesis, darle un nombre al archivo agregando el parámetro index=False para que no se agregue una nueva columna de índice:

datos.to_csv('datos_emisiones_co2.csv', index=False)
Copia el código
¡Listo! Pudimos leer datos de Google Sheets con la biblioteca Pandas e incluso guardamos el DataFrame que ahora se puede compartir con otras personas o ser utilizado en análisis posteriores.
*************************************************************************************++
 10 Lo que aprendimos
 Siguiente pregunta

En esta aula, aprendimos a:

Entender lo qué es una hoja de cálculo;
Leer un archivo en formato XLSX;
Identificar páginas en una hoja de trabajo;
Leer páginas e intervalos específicos de una hoja de trabajo;
Leer sólo unas pocas líneas de una hoja de cálculo;
Escribir un archivo en formato XLSX;
Importar datos de Google Sheets.
***************************************************
***************************************************
03.Leyendo archivos JSON
01 Proyecto del aula anterior
Si lo desea, puede descargar aquí el proyecto del curso en el punto donde paramos la clase anterior.
*****************************************************************+




